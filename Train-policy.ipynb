{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a7503d6f2b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_policy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_policy_ddpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_policies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearPolicy_MLPCritic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestartable_pendulum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRestartablePendulumEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/holden/Documents/CS/ml/LinearizingStateRepresentation/lib/train_policy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrnsteinUhlenbeckActionNoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppo2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macktr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACKTR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppo2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines/deepq/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMlpPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCnnPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLnMlpPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLnCnnPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_train\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrioritizedReplayBuffer\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines/deepq/policies.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "from lib.train_policy import train_policy_ddpg\n",
    "from lib.linear_policies import LinearPolicy_MLPCritic\n",
    "from lib.restartable_pendulum import RestartablePendulumEnv\n",
    "from lib.encoder_wrappers import EncoderWrapper, mlp_encoder           \n",
    "\n",
    "from gym.wrappers.time_limit import TimeLimit\n",
    "from stable_baselines.ddpg.policies import MlpPolicy, FeedForwardPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import DDPG\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # train the policy, then do some tests to get a sense of how it performs\n",
    "    \n",
    "    #for arg in sys.argv:\n",
    "    #    if arg.startswith('--job='):\n",
    "    #        i = int(arg.split('--job=')[1]) - 1\n",
    "    i=0\n",
    "    \n",
    "    # pull in the encoder params\n",
    "    p_dir =  \"./experiments/extra_train_exps/{}\".format(i)\n",
    "    proj = np.load(p_dir+\"projectors.npz\")\n",
    "    proj = np.row_stack([v for k,v in proj.items()])\n",
    "    proj = la.svd(proj,full_matrices=False)[2]\n",
    "    enc_dim = proj.shape[0]\n",
    "    weights = np.load(p_dir+\"weights.npz\")\n",
    "    biases = np.load(p_dir+\"biases.npz\")\n",
    "    weights = [v for k,v in weights.items()]\n",
    "    biases = [v for k,v in biases.items()]\n",
    "    \n",
    "    \n",
    "    saveload_path = \"./experiments/extra_train_exps/{}\".format(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # train the model\n",
    "    # try a few restarts, keep the best\n",
    "    best_avg_perf = -np.inf\n",
    "    perfs = []\n",
    "    for j in range(5):\n",
    "        # set up the environment\n",
    "        env = TimeLimit(RestartablePendulumEnv(enc_dim=enc_dim), max_episode_steps=200) # not sure effect of max_episode_steps\n",
    "        env = EncoderWrapper(env,mlp_encoder,[weights,biases,proj])\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "        pol = LinearPolicy_MLPCritic\n",
    "        pol_args = dict(layers=[64, 64],\n",
    "                        layer_norm=False) # this is the architecture for the critic in ddpg, doesn't specify policy\n",
    "    \n",
    "        model = train_policy_ddpg(env,pol,pol_args,300000,verbose=0,actor_lr=.5, critic_lr=.001)\n",
    "        \n",
    "        # clean up\n",
    "        env.close()\n",
    "\n",
    "\n",
    "        #model = DDPG.load(saveload_path+\"model\")\n",
    "\n",
    "        # now let's test the model \n",
    "        # specify the test task\n",
    "        n_test_steps = 100\n",
    "\n",
    "        # uniform grid over statespace (20 points)\n",
    "        angs = np.linspace(-np.pi, np.pi, 5)[:-1]\n",
    "        vels = np.linspace(-1, 1, 5)\n",
    "        test_states = np.array(list(itertools.product(angs,vels)))\n",
    "        n_test_states = len(angs)*len(vels)\n",
    "        performance = np.zeros(n_test_states)\n",
    "\n",
    "        # restart the env\n",
    "        env = TimeLimit(RestartablePendulumEnv(), max_episode_steps=200)\n",
    "        env = EncoderWrapper(env,mlp_encoder,[weights,biases,proj])\n",
    "\n",
    "        # for each test state, start the env in the state, then run forward and collect rewards\n",
    "        for k in range(n_test_states):\n",
    "            obs = env.reset(state=test_states[k])\n",
    "            rewards = []\n",
    "            for j in range(n_test_steps):\n",
    "                action, _states = model.predict(obs)\n",
    "                obs, reward, dones, info = env.step(action)\n",
    "                rewards.append(reward)\n",
    "                #env.render()\n",
    "            performance[k] = np.array(rewards).mean()\n",
    "\n",
    "        avg_perf = performance.mean()\n",
    "        perfs.append(avg_perf)\n",
    "        print(\"average performance of this model:{}\".format(avg_perf))\n",
    "        if avg_perf > best_avg_perf:\n",
    "            best_avg_perf = avg_perf\n",
    "            # specify the path to save the model\n",
    "            \n",
    "            model.save(saveload_path+\"model\")\n",
    "            np.savetxt(saveload_path+\"test_performance.txt\",performance)\n",
    "        \n",
    "        # clean up and save results\n",
    "        np.savetxt(saveload_path+\"avg_per_runs.txt\", np.array(perfs))\n",
    "        env.close()\n",
    "        del model\n",
    "        \n",
    "    \n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
